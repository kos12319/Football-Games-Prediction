{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Winning prediction from bettings odds of all 4 companies and team attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15981 entries, 0 to 15980\n",
      "Data columns (total 36 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   id_match                  15981 non-null  int64  \n",
      " 1   date_match                15981 non-null  object \n",
      " 2   season_name               15981 non-null  object \n",
      " 3   home_team_api_id          15981 non-null  int64  \n",
      " 4   away_team_api_id          15981 non-null  int64  \n",
      " 5   win_lose_draw             15981 non-null  object \n",
      " 6   B365H                     15981 non-null  float64\n",
      " 7   B365D                     15981 non-null  float64\n",
      " 8   B365A                     15981 non-null  float64\n",
      " 9   BWH                       15981 non-null  float64\n",
      " 10  BWD                       15981 non-null  float64\n",
      " 11  BWA                       15981 non-null  float64\n",
      " 12  IWH                       15981 non-null  float64\n",
      " 13  IWD                       15981 non-null  float64\n",
      " 14  IWA                       15981 non-null  float64\n",
      " 15  LBH                       15981 non-null  float64\n",
      " 16  LBD                       15981 non-null  float64\n",
      " 17  LBA                       15981 non-null  float64\n",
      " 18  buildUpPlaySpeed_H        15981 non-null  int64  \n",
      " 19  buildUpPlayPassing_H      15981 non-null  int64  \n",
      " 20  chanceCreationPassing_H   15981 non-null  int64  \n",
      " 21  chanceCreationCrossing_H  15981 non-null  int64  \n",
      " 22  chanceCreationShooting_H  15981 non-null  int64  \n",
      " 23  defencePressure_H         15981 non-null  int64  \n",
      " 24  defenceAggression_H       15981 non-null  int64  \n",
      " 25  defenceTeamWidth_H        15981 non-null  int64  \n",
      " 26  id                        15981 non-null  int64  \n",
      " 27  date                      15981 non-null  object \n",
      " 28  buildUpPlaySpeed_A        15981 non-null  int64  \n",
      " 29  buildUpPlayPassing_A      15981 non-null  int64  \n",
      " 30  chanceCreationPassing_A   15981 non-null  int64  \n",
      " 31  chanceCreationCrossing_A  15981 non-null  int64  \n",
      " 32  chanceCreationShooting_A  15981 non-null  int64  \n",
      " 33  defencePressure_A         15981 non-null  int64  \n",
      " 34  defenceAggression_A       15981 non-null  int64  \n",
      " 35  defenceTeamWidth_A        15981 non-null  int64  \n",
      "dtypes: float64(12), int64(20), object(4)\n",
      "memory usage: 4.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\KL\\Downloads\\archive\\/matches_with_team_attributes.csv')\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chanceCreationPassing_H', 'chanceCreationCrossing_A', 'BWD', 'buildUpPlayPassing_H', 'buildUpPlaySpeed_A', 'defencePressure_A', 'chanceCreationShooting_H', 'LBH', 'buildUpPlayPassing_A', 'LBD', 'IWD', 'LBA', 'defenceTeamWidth_A', 'B365H', 'chanceCreationCrossing_H', 'B365D', 'B365A', 'BWH', 'defenceTeamWidth_H', 'IWH', 'defenceAggression_A', 'buildUpPlaySpeed_H', 'defenceAggression_H', 'chanceCreationPassing_A', 'BWA', 'defencePressure_H', 'IWA', 'chanceCreationShooting_A']\n"
     ]
    }
   ],
   "source": [
    "#Prepare data and try different shallow models\n",
    "feature_cols = list(\n",
    "    set(df.columns.tolist()) - \n",
    "    {'id', 'date', 'match_api_id', 'home_team_api_id', 'away_team_api_id', 'win_lose_draw', 'season_name', 'date_match', 'id_match'}\n",
    "    )\n",
    "target_label = 'win_lose_draw'\n",
    "\n",
    "X = df[feature_cols]\n",
    "y = df[target_label]\n",
    "\n",
    "print(feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD2CAYAAAA6eVf+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAQ4klEQVR4nO3df6zddX3H8edLCro5Z4tcG9LWFWOnwT8E1gFGs0wbS8HFkkUZbhk3pEn3R93ULNlw/zSCJvjPmBgl6aRbMZvInI5GiXhTMdv+ALkIQwFJryBpG6BXb8UfRE3Ze3/cT+ex3ss9t9yeC3yej+TkfL7vz+d8z+ebS1/fL5/zPfemqpAk9eElyz0BSdLoGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR1ZsdwTeDZnnHFGrV+/frmnIUkvKPfcc8/3q2psrr7ndeivX7+eycnJ5Z6GJL2gJHlsvj6XdySpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdeV5/OWvU1l/15eWewkn1vWvfudxTkLTMvNKXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHVkw9JO8Psl9A48fJflAktOTTCTZ355XtfFJcn2SqST3JzlvYF/jbfz+JOMn88AkSb9uwdCvqoer6pyqOgf4PeBp4IvAVcC+qtoA7GvbABcDG9pjO3ADQJLTgZ3ABcD5wM5jJwpJ0mgsdnlnE/DdqnoM2ArsafU9wKWtvRW4qWbdCaxMciZwETBRVTNVdQSYALY81wOQJA1vsaF/OfDZ1l5dVY+39hPA6tZeAxwYeM3BVpuv/iuSbE8ymWRyenp6kdOTJD2boUM/yWnAu4B/O76vqgqopZhQVe2qqo1VtXFsbM6/6ytJOkGLudK/GPhmVT3Ztp9syza058OtfghYN/C6ta02X12SNCKLCf338sulHYC9wLE7cMaBWwfqV7S7eC4EnmrLQLcDm5Osah/gbm41SdKIDPVbNpO8HHgH8BcD5WuBW5JsAx4DLmv124BLgClm7/S5EqCqZpJcA9zdxl1dVTPP+QgkSUMbKvSr6qfAq46r/YDZu3mOH1vAjnn2sxvYvfhpSpKWgt/IlaSOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjoyVOgnWZnk80m+k+ShJG9OcnqSiST72/OqNjZJrk8yleT+JOcN7Ge8jd+fZPxkHZQkaW7DXul/HPhKVb0BeBPwEHAVsK+qNgD72jbAxcCG9tgO3ACQ5HRgJ3ABcD6w89iJQpI0GguGfpJXAn8A3AhQVb+oqh8CW4E9bdge4NLW3grcVLPuBFYmORO4CJioqpmqOgJMAFuW8FgkSQsY5kr/LGAa+Kck9yb5dJKXA6ur6vE25glgdWuvAQ4MvP5gq81X/xVJtieZTDI5PT29uKORJD2rYUJ/BXAecENVnQv8lF8u5QBQVQXUUkyoqnZV1caq2jg2NrYUu5QkNcOE/kHgYFXd1bY/z+xJ4Mm2bEN7Ptz6DwHrBl6/ttXmq0uSRmTB0K+qJ4ADSV7fSpuAB4G9wLE7cMaBW1t7L3BFu4vnQuCptgx0O7A5yar2Ae7mVpMkjciKIcf9JfAvSU4DHgGuZPaEcUuSbcBjwGVt7G3AJcAU8HQbS1XNJLkGuLuNu7qqZpbkKCRJQxkq9KvqPmDjHF2b5hhbwI559rMb2L2I+UmSlpDfyJWkjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6MlToJ/lekm8luS/JZKudnmQiyf72vKrVk+T6JFNJ7k9y3sB+xtv4/UnGT84hSZLms5gr/bdV1TlVdewPpF8F7KuqDcC+tg1wMbChPbYDN8DsSQLYCVwAnA/sPHaikCSNxnNZ3tkK7GntPcClA/WbatadwMokZwIXARNVNVNVR4AJYMtzeH9J0iING/oFfDXJPUm2t9rqqnq8tZ8AVrf2GuDAwGsPttp8dUnSiKwYctxbq+pQklcDE0m+M9hZVZWklmJC7aSyHeA1r3nNUuxSktQMdaVfVYfa82Hgi8yuyT/Zlm1oz4fb8EPAuoGXr221+erHv9euqtpYVRvHxsYWdzSSpGe1YOgneXmSVxxrA5uBbwN7gWN34IwDt7b2XuCKdhfPhcBTbRnodmBzklXtA9zNrSZJGpFhlndWA19Mcmz8v1bVV5LcDdySZBvwGHBZG38bcAkwBTwNXAlQVTNJrgHubuOurqqZJTsSSdKCFgz9qnoEeNMc9R8Am+aoF7Bjnn3tBnYvfpqSpKXgN3IlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSR4b9NQzS8976q7683FM4qb537TuXewp6EfBKX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdGTr0k5yS5N4kX2rbZyW5K8lUks8lOa3VX9q2p1r/+oF9fKjVH05y0ZIfjSTpWS3mSv/9wEMD2x8Drquq1wFHgG2tvg040urXtXEkORu4HHgjsAX4VJJTntv0JUmLMVToJ1kLvBP4dNsO8Hbg823IHuDS1t7atmn9m9r4rcDNVfXzqnoUmALOX4JjkCQNadjfp/8PwN8Ar2jbrwJ+WFVH2/ZBYE1rrwEOAFTV0SRPtfFrgDsH9jn4Gkkd828hjM6CV/pJ/gg4XFX3jGA+JNmeZDLJ5PT09CjeUpK6MczyzluAdyX5HnAzs8s6HwdWJjn2fwprgUOtfQhYB9D6Xwn8YLA+x2v+X1XtqqqNVbVxbGxs0QckSZrfgqFfVR+qqrVVtZ7ZD2K/VlV/BtwBvLsNGwdube29bZvW/7Wqqla/vN3dcxawAfjGkh2JJGlBz+Vv5P4tcHOSjwD3Aje2+o3AZ5JMATPMniioqgeS3AI8CBwFdlTVM8/h/SVJi7So0K+qrwNfb+1HmOPum6r6GfCeeV7/UeCji52kJGlp+I1cSeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSMLhn6SlyX5RpL/SfJAkg+3+llJ7koyleRzSU5r9Ze27anWv35gXx9q9YeTXHTSjkqSNKdhrvR/Dry9qt4EnANsSXIh8DHguqp6HXAE2NbGbwOOtPp1bRxJzgYuB94IbAE+leSUJTwWSdICFgz9mvWTtnlqexTwduDzrb4HuLS1t7ZtWv+mJGn1m6vq51X1KDAFnL8UByFJGs5Qa/pJTklyH3AYmAC+C/ywqo62IQeBNa29BjgA0PqfAl41WJ/jNZKkERgq9Kvqmao6B1jL7NX5G07WhJJsTzKZZHJ6evpkvY0kdWlRd+9U1Q+BO4A3AyuTrGhda4FDrX0IWAfQ+l8J/GCwPsdrBt9jV1VtrKqNY2Nji5meJGkBw9y9M5ZkZWv/BvAO4CFmw//dbdg4cGtr723btP6vVVW1+uXt7p6zgA3AN5boOCRJQ1ix8BDOBPa0O21eAtxSVV9K8iBwc5KPAPcCN7bxNwKfSTIFzDB7xw5V9UCSW4AHgaPAjqp6ZmkPR5L0bBYM/aq6Hzh3jvojzHH3TVX9DHjPPPv6KPDRxU9TkrQU/EauJHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1JEFQz/JuiR3JHkwyQNJ3t/qpyeZSLK/Pa9q9SS5PslUkvuTnDewr/E2fn+S8ZN3WJKkuQxzpX8U+OuqOhu4ENiR5GzgKmBfVW0A9rVtgIuBDe2xHbgBZk8SwE7gAmb/oPrOYycKSdJoLBj6VfV4VX2ztX8MPASsAbYCe9qwPcClrb0VuKlm3QmsTHImcBEwUVUzVXUEmAC2LOXBSJKe3aLW9JOsB84F7gJWV9XjresJYHVrrwEODLzsYKvNV5ckjcjQoZ/kt4B/Bz5QVT8a7KuqAmopJpRke5LJJJPT09NLsUtJUjNU6Cc5ldnA/5eq+kIrP9mWbWjPh1v9ELBu4OVrW22++q+oql1VtbGqNo6NjS3mWCRJCxjm7p0ANwIPVdXfD3TtBY7dgTMO3DpQv6LdxXMh8FRbBrod2JxkVfsAd3OrSZJGZMUQY94C/DnwrST3tdrfAdcCtyTZBjwGXNb6bgMuAaaAp4ErAapqJsk1wN1t3NVVNbMUByFJGs6CoV9V/w1knu5Nc4wvYMc8+9oN7F7MBCVJS8dv5EpSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSMLhn6S3UkOJ/n2QO30JBNJ9rfnVa2eJNcnmUpyf5LzBl4z3sbvTzJ+cg5HkvRshrnS/2dgy3G1q4B9VbUB2Ne2AS4GNrTHduAGmD1JADuBC4DzgZ3HThSSpNFZMPSr6j+BmePKW4E9rb0HuHSgflPNuhNYmeRM4CJgoqpmquoIMMGvn0gkSSfZia7pr66qx1v7CWB1a68BDgyMO9hq89V/TZLtSSaTTE5PT5/g9CRJc3nOH+RWVQG1BHM5tr9dVbWxqjaOjY0t1W4lSZx46D/Zlm1oz4db/RCwbmDc2labry5JGqETDf29wLE7cMaBWwfqV7S7eC4EnmrLQLcDm5Osah/gbm41SdIIrVhoQJLPAn8InJHkILN34VwL3JJkG/AYcFkbfhtwCTAFPA1cCVBVM0muAe5u466uquM/HJYknWQLhn5VvXeerk1zjC1gxzz72Q3sXtTsJElLym/kSlJHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0Zeegn2ZLk4SRTSa4a9ftLUs9GGvpJTgE+CVwMnA28N8nZo5yDJPVs1Ff65wNTVfVIVf0CuBnYOuI5SFK3Voz4/dYABwa2DwIXDA5Ish3Y3jZ/kuThEc1tOZwBfH9Ub5aPjeqduuHP74Xrxf6z+535OkYd+guqql3AruWexygkmayqjcs9D50Yf34vXD3/7Ea9vHMIWDewvbbVJEkjMOrQvxvYkOSsJKcBlwN7RzwHSerWSJd3qupokvcBtwOnALur6oFRzuF5potlrBcxf34vXN3+7FJVyz0HSdKI+I1cSeqIoS9JHTH0Jakjhr50gpK8Ncknl3seGl6SsSRjyz2P5fS8+3LWi1WSTwDzfmpeVX81wunoBCU5F/hT4D3Ao8AXlndGWkiSADuB9zF7oZskR4FPVNXVyzq5ZWDoj87kQPvDzP5HqBeAJL8LvLc9vg98jtk73962rBPTsD4IvAX4/ap6FCDJa4Ebknywqq5b1tmNmLdsLoMk91bVucs9Dw0nyf8C/wVsq6qpVnukql67vDPTMJLcC7yjqr5/XH0M+Gpv/xZd018enmlfWP4YeBy4I8k/JtkEZJnnpOGdenzgA1TVNHDqMsxnWRn60gKq6j+q6nLgDcAdwAeAVye5IcnmZZ2chvGLE+x7UXJ5Z0SS/JhfXuH/JvD0sS6gquq3l2ViOiFJVjH7Ye6fVNWm5Z6P5pfkGeCnc3UBL6uqrq72DX1J6ojLO5LUEUNfkjpi6EtSRwx9SeqIoS9JHfk/x2SknbdPdA8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic regression classifier on training set: 0.53\n",
      "Accuracy of Logistic regression classifier on test set: 0.54\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy of Logistic regression classifier on training set: {:.2f}'\n",
    "     .format(logreg.score(X_train, y_train)))\n",
    "print('Accuracy of Logistic regression classifier on test set: {:.2f}'\n",
    "     .format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KL\\Envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\KL\\Envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\KL\\Envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\KL\\Envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\KL\\Envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\KL\\Envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\KL\\Envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\KL\\Envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\KL\\Envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.533 (0.014)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KL\\Envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#A shot at 10 fold cross validation\n",
    "from numpy import mean, std\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "scores = cross_val_score(LogisticRegression(), X, y, cv=KFold(n_splits=10, random_state=42, shuffle=True))\n",
    "\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on training set: 1.00\n",
      "Accuracy of Decision Tree classifier on test set: 0.42\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=42).fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, y_train)))\n",
    "print('Accuracy of Decision Tree classifier on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.423 (0.013)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(DecisionTreeClassifier(), X, y, cv=KFold(n_splits=10, random_state=42, shuffle=True))\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of K-NN classifier on training set: 0.68\n",
      "Accuracy of K-NN classifier on test set: 0.45\n"
     ]
    }
   ],
   "source": [
    "#K-nearest neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy of K-NN classifier on training set: {:.2f}'\n",
    "     .format(knn.score(X_train, y_train)))\n",
    "print('Accuracy of K-NN classifier on test set: {:.2f}'\n",
    "     .format(knn.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.426 (0.014)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(KNeighborsClassifier(), X, y, cv=KFold(n_splits=10, random_state=42, shuffle=True))\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of LDA classifier on training set: 0.53\n",
      "Accuracy of LDA classifier on test set: 0.54\n"
     ]
    }
   ],
   "source": [
    "# Linear Discriminant Analysis\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy of LDA classifier on training set: {:.2f}'\n",
    "     .format(lda.score(X_train, y_train)))\n",
    "print('Accuracy of LDA classifier on test set: {:.2f}'\n",
    "     .format(lda.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.529 (0.014)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(LinearDiscriminantAnalysis(), X, y, cv=KFold(n_splits=10, random_state=42, shuffle=True))\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of GNB classifier on training set: 0.42\n",
      "Accuracy of GNB classifier on test set: 0.42\n"
     ]
    }
   ],
   "source": [
    "#Gau√üian Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy of GNB classifier on training set: {:.2f}'\n",
    "     .format(gnb.score(X_train, y_train)))\n",
    "print('Accuracy of GNB classifier on test set: {:.2f}'\n",
    "     .format(gnb.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.418 (0.010)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(GaussianNB(), X, y, cv=KFold(n_splits=10, random_state=42, shuffle=True))\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM classifier on training set: 0.52\n",
      "Accuracy of SVM classifier on test set: 0.53\n"
     ]
    }
   ],
   "source": [
    "#Support Vector Machine\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(kernel='linear')\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy of SVM classifier on training set: {:.2f}'\n",
    "     .format(svm.score(X_train, y_train)))\n",
    "print('Accuracy of SVM classifier on test set: {:.2f}'\n",
    "     .format(svm.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mUntitled-2.ipynb Cell 18'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:Untitled-2.ipynb?jupyter-notebook#ch0000020untitled?line=0'>1</a>\u001b[0m scores \u001b[39m=\u001b[39m cross_val_score(SVC(), X, y, cv\u001b[39m=\u001b[39;49mKFold(n_splits\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, random_state\u001b[39m=\u001b[39;49m\u001b[39m42\u001b[39;49m, shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m))\n\u001b[0;32m      <a href='vscode-notebook-cell:Untitled-2.ipynb?jupyter-notebook#ch0000020untitled?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mAccuracy: \u001b[39m\u001b[39m%.3f\u001b[39;00m\u001b[39m (\u001b[39m\u001b[39m%.3f\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m (mean(scores), std(scores)))\n",
      "File \u001b[1;32mc:\\Users\\KL\\Envs\\test\\lib\\site-packages\\sklearn\\utils\\validation.py:63\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/utils/validation.py?line=60'>61</a>\u001b[0m extra_args \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(args) \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(all_args)\n\u001b[0;32m     <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/utils/validation.py?line=61'>62</a>\u001b[0m \u001b[39mif\u001b[39;00m extra_args \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m---> <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/utils/validation.py?line=62'>63</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/utils/validation.py?line=64'>65</a>\u001b[0m \u001b[39m# extra_args > 0\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/utils/validation.py?line=65'>66</a>\u001b[0m args_msg \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(name, arg)\n\u001b[0;32m     <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/utils/validation.py?line=66'>67</a>\u001b[0m             \u001b[39mfor\u001b[39;00m name, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(kwonly_args[:extra_args],\n\u001b[0;32m     <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/utils/validation.py?line=67'>68</a>\u001b[0m                                  args[\u001b[39m-\u001b[39mextra_args:])]\n",
      "File \u001b[1;32mc:\\Users\\KL\\Envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:445\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/model_selection/_validation.py?line=441'>442</a>\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/model_selection/_validation.py?line=442'>443</a>\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[1;32m--> <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/model_selection/_validation.py?line=444'>445</a>\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(estimator\u001b[39m=\u001b[39;49mestimator, X\u001b[39m=\u001b[39;49mX, y\u001b[39m=\u001b[39;49my, groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/model_selection/_validation.py?line=445'>446</a>\u001b[0m                             scoring\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m'\u001b[39;49m: scorer}, cv\u001b[39m=\u001b[39;49mcv,\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/model_selection/_validation.py?line=446'>447</a>\u001b[0m                             n_jobs\u001b[39m=\u001b[39;49mn_jobs, verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/model_selection/_validation.py?line=447'>448</a>\u001b[0m                             fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/model_selection/_validation.py?line=448'>449</a>\u001b[0m                             pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/model_selection/_validation.py?line=449'>450</a>\u001b[0m                             error_score\u001b[39m=\u001b[39;49merror_score)\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/model_selection/_validation.py?line=450'>451</a>\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m'\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\KL\\Envs\\test\\lib\\site-packages\\sklearn\\utils\\validation.py:63\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/utils/validation.py?line=60'>61</a>\u001b[0m extra_args \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(args) \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(all_args)\n\u001b[0;32m     <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/utils/validation.py?line=61'>62</a>\u001b[0m \u001b[39mif\u001b[39;00m extra_args \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m---> <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/utils/validation.py?line=62'>63</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/utils/validation.py?line=64'>65</a>\u001b[0m \u001b[39m# extra_args > 0\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/utils/validation.py?line=65'>66</a>\u001b[0m args_msg \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(name, arg)\n\u001b[0;32m     <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/utils/validation.py?line=66'>67</a>\u001b[0m             \u001b[39mfor\u001b[39;00m name, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(kwonly_args[:extra_args],\n\u001b[0;32m     <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/utils/validation.py?line=67'>68</a>\u001b[0m                                  args[\u001b[39m-\u001b[39mextra_args:])]\n",
      "File \u001b[1;32mc:\\Users\\KL\\Envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:250\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/model_selection/_validation.py?line=245'>246</a>\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/model_selection/_validation.py?line=246'>247</a>\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/model_selection/_validation.py?line=247'>248</a>\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose,\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/model_selection/_validation.py?line=248'>249</a>\u001b[0m                     pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/model_selection/_validation.py?line=249'>250</a>\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/model_selection/_validation.py?line=250'>251</a>\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/model_selection/_validation.py?line=251'>252</a>\u001b[0m         clone(estimator), X, y, scorers, train, test, verbose, \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/model_selection/_validation.py?line=252'>253</a>\u001b[0m         fit_params, return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/model_selection/_validation.py?line=253'>254</a>\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/model_selection/_validation.py?line=254'>255</a>\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score)\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/model_selection/_validation.py?line=255'>256</a>\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/model_selection/_validation.py?line=257'>258</a>\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/model_selection/_validation.py?line=258'>259</a>\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/model_selection/_validation.py?line=259'>260</a>\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/model_selection/_validation.py?line=260'>261</a>\u001b[0m \u001b[39mif\u001b[39;00m callable(scoring):\n",
      "File \u001b[1;32mc:\\Users\\KL\\Envs\\test\\lib\\site-packages\\joblib\\parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/joblib/parallel.py?line=1042'>1043</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/joblib/parallel.py?line=1043'>1044</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/joblib/parallel.py?line=1045'>1046</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/joblib/parallel.py?line=1046'>1047</a>\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/joblib/parallel.py?line=1048'>1049</a>\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/joblib/parallel.py?line=1049'>1050</a>\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/joblib/parallel.py?line=1050'>1051</a>\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/joblib/parallel.py?line=1051'>1052</a>\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\KL\\Envs\\test\\lib\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/joblib/parallel.py?line=858'>859</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/joblib/parallel.py?line=859'>860</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/joblib/parallel.py?line=860'>861</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/joblib/parallel.py?line=861'>862</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\KL\\Envs\\test\\lib\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/joblib/parallel.py?line=776'>777</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/joblib/parallel.py?line=777'>778</a>\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/joblib/parallel.py?line=778'>779</a>\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/joblib/parallel.py?line=779'>780</a>\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/joblib/parallel.py?line=780'>781</a>\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/joblib/parallel.py?line=781'>782</a>\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/joblib/parallel.py?line=782'>783</a>\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/joblib/parallel.py?line=783'>784</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\KL\\Envs\\test\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/joblib/_parallel_backends.py?line=205'>206</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/joblib/_parallel_backends.py?line=206'>207</a>\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/joblib/_parallel_backends.py?line=207'>208</a>\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/joblib/_parallel_backends.py?line=208'>209</a>\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/joblib/_parallel_backends.py?line=209'>210</a>\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\KL\\Envs\\test\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/joblib/_parallel_backends.py?line=568'>569</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/joblib/_parallel_backends.py?line=569'>570</a>\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/joblib/_parallel_backends.py?line=570'>571</a>\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/joblib/_parallel_backends.py?line=571'>572</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\KL\\Envs\\test\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/joblib/parallel.py?line=257'>258</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/joblib/parallel.py?line=258'>259</a>\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/joblib/parallel.py?line=259'>260</a>\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/joblib/parallel.py?line=260'>261</a>\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/joblib/parallel.py?line=261'>262</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/joblib/parallel.py?line=262'>263</a>\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\KL\\Envs\\test\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/joblib/parallel.py?line=257'>258</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/joblib/parallel.py?line=258'>259</a>\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/joblib/parallel.py?line=259'>260</a>\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/joblib/parallel.py?line=260'>261</a>\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/joblib/parallel.py?line=261'>262</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/joblib/parallel.py?line=262'>263</a>\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\KL\\Envs\\test\\lib\\site-packages\\sklearn\\utils\\fixes.py:222\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/utils/fixes.py?line=219'>220</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/utils/fixes.py?line=220'>221</a>\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[1;32m--> <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/utils/fixes.py?line=221'>222</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\KL\\Envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:598\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/model_selection/_validation.py?line=595'>596</a>\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/model_selection/_validation.py?line=596'>597</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/model_selection/_validation.py?line=597'>598</a>\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, y_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/model_selection/_validation.py?line=599'>600</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/model_selection/_validation.py?line=600'>601</a>\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/model_selection/_validation.py?line=601'>602</a>\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\KL\\Envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py:226\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/svm/_base.py?line=222'>223</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m[LibSVM]\u001b[39m\u001b[39m'\u001b[39m, end\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/svm/_base.py?line=224'>225</a>\u001b[0m seed \u001b[39m=\u001b[39m rnd\u001b[39m.\u001b[39mrandint(np\u001b[39m.\u001b[39miinfo(\u001b[39m'\u001b[39m\u001b[39mi\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mmax)\n\u001b[1;32m--> <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/svm/_base.py?line=225'>226</a>\u001b[0m fit(X, y, sample_weight, solver_type, kernel, random_seed\u001b[39m=\u001b[39;49mseed)\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/svm/_base.py?line=226'>227</a>\u001b[0m \u001b[39m# see comment on the other call to np.iinfo in this file\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/svm/_base.py?line=228'>229</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape_fit_ \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(X, \u001b[39m\"\u001b[39m\u001b[39mshape\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m (n_samples, )\n",
      "File \u001b[1;32mc:\\Users\\KL\\Envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py:277\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/svm/_base.py?line=270'>271</a>\u001b[0m libsvm\u001b[39m.\u001b[39mset_verbosity_wrap(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/svm/_base.py?line=272'>273</a>\u001b[0m \u001b[39m# we don't pass **self.get_params() to allow subclasses to\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/svm/_base.py?line=273'>274</a>\u001b[0m \u001b[39m# add other parameters to __init__\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/svm/_base.py?line=274'>275</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupport_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupport_vectors_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_support, \\\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/svm/_base.py?line=275'>276</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdual_coef_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintercept_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_probA, \\\n\u001b[1;32m--> <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/svm/_base.py?line=276'>277</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_probB, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_status_ \u001b[39m=\u001b[39m libsvm\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/svm/_base.py?line=277'>278</a>\u001b[0m         X, y,\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/svm/_base.py?line=278'>279</a>\u001b[0m         svm_type\u001b[39m=\u001b[39;49msolver_type, sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/svm/_base.py?line=279'>280</a>\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight_, kernel\u001b[39m=\u001b[39;49mkernel, C\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mC,\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/svm/_base.py?line=280'>281</a>\u001b[0m         nu\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnu, probability\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprobability, degree\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdegree,\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/svm/_base.py?line=281'>282</a>\u001b[0m         shrinking\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshrinking, tol\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtol,\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/svm/_base.py?line=282'>283</a>\u001b[0m         cache_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcache_size, coef0\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcoef0,\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/svm/_base.py?line=283'>284</a>\u001b[0m         gamma\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_gamma, epsilon\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepsilon,\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/svm/_base.py?line=284'>285</a>\u001b[0m         max_iter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter, random_seed\u001b[39m=\u001b[39;49mrandom_seed)\n\u001b[0;32m    <a href='file:///c%3A/Users/KL/Envs/test/lib/site-packages/sklearn/svm/_base.py?line=286'>287</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_warn_from_fit_status()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(SVC(), X, y, cv=KFold(n_splits=10, random_state=42, shuffle=True))\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-layer perceptron\n",
    "# Linear MLP, single hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of MLP classifier on training set: 0.53\n",
      "Accuracy of MLP classifier on test set: 0.54\n"
     ]
    }
   ],
   "source": [
    "# One layer of 1 neuron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "plot = MLPClassifier(random_state=42, activation='identity', hidden_layer_sizes=(1,))\n",
    "plot.fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy of MLP classifier on training set: {:.2f}'\n",
    "     .format(plot.score(X_train, y_train)))\n",
    "print('Accuracy of MLP classifier on test set: {:.2f}'\n",
    "     .format(plot.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.532 (0.015)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(plot, X, y, cv=KFold(n_splits=10, random_state=42, shuffle=True))\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of MLP classifier on training set: 0.53\n",
      "Accuracy of MLP classifier on test set: 0.54\n"
     ]
    }
   ],
   "source": [
    "#One layer of 10 neurons\n",
    "mlp = MLPClassifier(random_state=42, activation='identity', hidden_layer_sizes=(10,))\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy of MLP classifier on training set: {:.2f}'\n",
    "     .format(mlp.score(X_train, y_train)))\n",
    "print('Accuracy of MLP classifier on test set: {:.2f}'\n",
    "     .format(mlp.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.524 (0.018)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(mlp, X, y, cv=KFold(n_splits=10, random_state=42, shuffle=True))\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of MLP classifier on training set: 0.53\n",
      "Accuracy of MLP classifier on test set: 0.54\n"
     ]
    }
   ],
   "source": [
    "#Linear MLP, two hidden layers\n",
    "mlp = MLPClassifier(random_state=42, activation='identity', hidden_layer_sizes=(1,1))\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy of MLP classifier on training set: {:.2f}'\n",
    "     .format(mlp.score(X_train, y_train)))\n",
    "print('Accuracy of MLP classifier on test set: {:.2f}'\n",
    "     .format(mlp.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.531 (0.015)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(mlp, X, y, cv=KFold(n_splits=10, random_state=42, shuffle=True))\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of MLP classifier on training set: 0.53\n",
      "Accuracy of MLP classifier on test set: 0.54\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(random_state=42, activation='identity', hidden_layer_sizes=(10,10))\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy of MLP classifier on training set: {:.2f}'\n",
    "     .format(mlp.score(X_train, y_train)))\n",
    "print('Accuracy of MLP classifier on test set: {:.2f}'\n",
    "     .format(mlp.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of MLP classifier on training set: 0.84\n",
      "Accuracy of MLP classifier on test set: 0.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KL\\Envs\\test\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(random_state=42, activation='relu', hidden_layer_sizes=(100,100))\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy of MLP classifier on training set: {:.2f}'\n",
    "     .format(mlp.score(X_train, y_train)))\n",
    "print('Accuracy of MLP classifier on test set: {:.2f}'\n",
    "     .format(mlp.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of MLP classifier on training set: 0.55\n",
      "Accuracy of MLP classifier on test set: 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KL\\Envs\\test\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Non-linear MLP, three hidden layers and more\n",
    "mlp = MLPClassifier(random_state=42, activation='relu', hidden_layer_sizes=(10, 10, 10))\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy of MLP classifier on training set: {:.2f}'\n",
    "     .format(mlp.score(X_train, y_train)))\n",
    "print('Accuracy of MLP classifier on test set: {:.2f}'\n",
    "     .format(mlp.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of MLP classifier on training set: 0.55\n",
      "Accuracy of MLP classifier on test set: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KL\\Envs\\test\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(random_state=42, activation='relu', hidden_layer_sizes=(10, 10, 10, 10, 10))\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy of MLP classifier on training set: {:.2f}'\n",
    "     .format(mlp.score(X_train, y_train)))\n",
    "print('Accuracy of MLP classifier on test set: {:.2f}'\n",
    "     .format(mlp.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of MLP classifier on training set: 0.98\n",
      "Accuracy of MLP classifier on test set: 0.45\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(random_state=42, activation='relu', hidden_layer_sizes=(100, 100, 100, 100, 100))\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy of MLP classifier on training set: {:.2f}'\n",
    "     .format(mlp.score(X_train, y_train)))\n",
    "print('Accuracy of MLP classifier on test set: {:.2f}'\n",
    "     .format(mlp.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix of Logistic Regression\n",
    "Logistic Regression was the best performing simplest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 429    5  502]\n",
      " [ 182    1  608]\n",
      " [ 170    0 1300]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.55      0.46      0.50       936\n",
      "           D       0.17      0.00      0.00       791\n",
      "           H       0.54      0.88      0.67      1470\n",
      "\n",
      "    accuracy                           0.54      3197\n",
      "   macro avg       0.42      0.45      0.39      3197\n",
      "weighted avg       0.45      0.54      0.46      3197\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "pred = logreg.predict(X_test)\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dd6fd8107bae2689530a6e3c29c63883cc6c3a18785e969a7207aa9b23fcbe43"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
